{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "201f9121-2b46-4d01-88b5-43e9423ae71a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d2f7a0d56a0489c8ae282883c2db1b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/16000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe657d29a5a6458386989462e7cdf277",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/2000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc4808f3914b4a1294347d5d558aa1e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/2000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset re-labeled and saved to /Users/bilalkhalid/Desktop/TUS/S2/Project/Sprint2/UpdatedDataSet\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, ClassLabel\n",
    "\n",
    "dataset = load_dataset(\"dair-ai/emotion\")\n",
    "standard_emotions = [\"neutral\", \"happy\", \"surprise\", \"sad\", \"angry\", \"fear\", \"disgust\"]\n",
    "\n",
    "original_to_standard = {\n",
    "    0: 3,  # sadness -> sad\n",
    "    1: 1,  # joy -> happy\n",
    "    2: 1,  # love -> happy\n",
    "    3: 4,  # anger -> angry\n",
    "    4: 5,  # fear -> fear\n",
    "    5: 2   # surprise -> surprise\n",
    "}\n",
    "\n",
    "\n",
    "def map_label(example):\n",
    "    example[\"label\"] = original_to_standard[example[\"label\"]]\n",
    "    return example\n",
    "\n",
    "dataset = dataset.map(map_label)\n",
    "dataset = dataset.cast_column(\"label\", ClassLabel(names=standard_emotions))\n",
    "\n",
    "\n",
    "output_path = \"/Users/bilalkhalid/Desktop/TUS/S2/Project/Sprint2/UpdatedDataSet\"\n",
    "dataset.save_to_disk(output_path)\n",
    "\n",
    "print(f\"Dataset re-labeled and saved to {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1c561311-1ae7-422d-84f1-89cb33d074ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Schema: {'text': Value(dtype='string', id=None), 'label': ClassLabel(names=['neutral', 'happy', 'surprise', 'sad', 'angry', 'fear', 'disgust'], id=None)}\n",
      "Label feature names: ['neutral', 'happy', 'surprise', 'sad', 'angry', 'fear', 'disgust']\n",
      "train split: All labels are valid (0-6)\n",
      "validation split: All labels are valid (0-6)\n",
      "test split: All labels are valid (0-6)\n",
      "\n",
      "First 5 examples from train:\n",
      "Text: i didnt feel humiliated... | Label: 3 (sad)\n",
      "Text: i can go from feeling so hopeless to so damned hop... | Label: 3 (sad)\n",
      "Text: im grabbing a minute to post i feel greedy wrong... | Label: 4 (angry)\n",
      "Text: i am ever feeling nostalgic about the fireplace i ... | Label: 1 (happy)\n",
      "Text: i am feeling grouchy... | Label: 4 (angry)\n",
      "train split: No missing data\n",
      "validation split: No missing data\n",
      "test split: No missing data\n",
      "\n",
      "Label Distribution Across All Splits:\n",
      "0: neutral - 0 instances\n",
      "1: happy - 8402 instances\n",
      "2: surprise - 719 instances\n",
      "3: sad - 5797 instances\n",
      "4: angry - 2709 instances\n",
      "5: fear - 2373 instances\n",
      "6: disgust - 0 instances\n",
      "\n",
      "Validation successful: Dataset is correctly formatted with 20,000 examples.\n"
     ]
    }
   ],
   "source": [
    "# Validating\n",
    "from datasets import load_from_disk, ClassLabel\n",
    "from collections import Counter\n",
    "\n",
    "dataset_path = \"/Users/bilalkhalid/Desktop/TUS/S2/Project/Sprint2/UpdatedDataSet\"\n",
    "dataset = load_from_disk(dataset_path)\n",
    "\n",
    "standard_emotions = [\"neutral\", \"happy\", \"surprise\", \"sad\", \"angry\", \"fear\", \"disgust\"]\n",
    "\n",
    "# --- Verification Steps ---\n",
    "\n",
    "# 1. Check dataset schema\n",
    "print(\"Dataset Schema:\", dataset[\"train\"].features)\n",
    "if isinstance(dataset[\"train\"].features[\"label\"], ClassLabel):\n",
    "    print(\"Label feature names:\", dataset[\"train\"].features[\"label\"].names)\n",
    "    if dataset[\"train\"].features[\"label\"].names != standard_emotions:\n",
    "        raise ValueError(\"Label names do not match the standard emotions\")\n",
    "else:\n",
    "    raise ValueError(\"Label feature is not a ClassLabel\")\n",
    "\n",
    "# 2. Validate label values\n",
    "for split in [\"train\", \"validation\", \"test\"]:\n",
    "    labels = dataset[split][\"label\"]\n",
    "    invalid_labels = [label for label in labels if label not in range(7)]\n",
    "    if invalid_labels:\n",
    "        print(f\"Error in {split}: Invalid labels found: {invalid_labels}\")\n",
    "    else:\n",
    "        print(f\"{split} split: All labels are valid (0-6)\")\n",
    "\n",
    "# 3. Sample verification\n",
    "print(\"\\nFirst 5 examples from train:\")\n",
    "for i in range(min(5, len(dataset[\"train\"]))):\n",
    "    text = dataset[\"train\"][i][\"text\"]\n",
    "    label_idx = dataset[\"train\"][i][\"label\"]\n",
    "    label_name = standard_emotions[label_idx]\n",
    "    print(f\"Text: {text[:50]}... | Label: {label_idx} ({label_name})\")\n",
    "\n",
    "# 4. Check for missing data\n",
    "for split in [\"train\", \"validation\", \"test\"]:\n",
    "    missing_labels = [i for i, ex in enumerate(dataset[split]) if ex[\"label\"] is None]\n",
    "    missing_texts = [i for i, ex in enumerate(dataset[split]) if not ex[\"text\"]]\n",
    "    if missing_labels or missing_texts:\n",
    "        print(f\"Error in {split}: Missing labels at {missing_labels}, Missing texts at {missing_texts}\")\n",
    "    else:\n",
    "        print(f\"{split} split: No missing data\")\n",
    "\n",
    "# 5. Label distribution\n",
    "all_labels = []\n",
    "for split in dataset.keys():\n",
    "    all_labels.extend(dataset[split][\"label\"])\n",
    "label_counts = Counter(all_labels)\n",
    "print(\"\\nLabel Distribution Across All Splits:\")\n",
    "for i, emotion in enumerate(standard_emotions):\n",
    "    count = label_counts.get(i, 0)\n",
    "    print(f\"{i}: {emotion} - {count} instances\")\n",
    "\n",
    "# Final confirmation\n",
    "total_examples = sum(len(dataset[split]) for split in dataset.keys())\n",
    "if total_examples == 20000 and sum(label_counts.values()) == 20000:\n",
    "    # print(\"ABC 1\")\n",
    "    print(\"\\nValidation successful: Dataset is correctly formatted with 20,000 examples.\")\n",
    "else:\n",
    "    # print(\"Error ABC 2\")\n",
    "    print(f\"\\nWarning: Expected 20,000 examples, but found {total_examples} with {sum(label_counts.values())} labeled instances.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4572b92c-4b61-4ea2-a841-89984fc7b405",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
