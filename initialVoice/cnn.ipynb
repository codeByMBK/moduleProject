{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4eb7d4c7-d32e-4951-b6c6-324dd4e76a7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import librosa\n",
    "import librosa.display\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "print('2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ac372868-c6d1-439d-ae10-b998253497bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ X shape: (1440, 128, 128, 1)\n",
      "✅ y shape: (1440,)\n",
      "✅ X min: 0.0, X max: 1.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "DATASET_PATH = \"RAVDESS Emotional speech audio\"  # 你的 RAVDESS 数据集路径\n",
    "LABELS = {\n",
    "    \"neutral\": 1, \"calm\": 2, \"happy\": 3, \"sad\": 4, \"angry\": 5,\n",
    "    \"fearful\": 6, \"disgust\": 7, \"surprised\": 8\n",
    "}  # 你可以调整这些标签\n",
    "\n",
    "def extract_features(file_path, max_pad_length=128):\n",
    "    y, sr = librosa.load(file_path, sr=22050)  # 读取音频\n",
    "    mel_spec = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=128, hop_length=512)  # 计算 Mel 频谱\n",
    "    mel_spec_db = librosa.power_to_db(mel_spec, ref=np.max)  # 转换为 dB 形式\n",
    "\n",
    "    # 归一化到 [0,1]\n",
    "    mel_spec_db = (mel_spec_db + 80) / 80\n",
    "\n",
    "    # 统一 shape：填充或裁剪到 (128, max_pad_length)\n",
    "    if mel_spec_db.shape[1] < max_pad_length:\n",
    "        pad_width = max_pad_length - mel_spec_db.shape[1]\n",
    "        mel_spec_db = np.pad(mel_spec_db, ((0, 0), (0, pad_width)), mode='constant')\n",
    "    else:\n",
    "        mel_spec_db = mel_spec_db[:, :max_pad_length]\n",
    "\n",
    "    return mel_spec_db\n",
    "\n",
    "X, y = [], []\n",
    "for actor_folder in os.listdir(DATASET_PATH):\n",
    "    actor_path = os.path.join(DATASET_PATH, actor_folder)\n",
    "    if not os.path.isdir(actor_path):\n",
    "        continue  # 跳过非文件夹\n",
    "\n",
    "    for file in os.listdir(actor_path):\n",
    "        if file.endswith(\".wav\"):\n",
    "            file_path = os.path.join(actor_path, file)\n",
    "            \n",
    "            # 从文件名解析情绪类别（第 3 个字段）\n",
    "            emotion_code = int(file.split(\"-\")[2])\n",
    "            \n",
    "            # 计算 Mel 频谱特征\n",
    "            feature = extract_features(file_path)\n",
    "            X.append(feature)\n",
    "            y.append(emotion_code)\n",
    "\n",
    "# 转换为 NumPy 数组\n",
    "X = np.array(X)  # (样本数, 128, max_pad_length)\n",
    "X = np.expand_dims(X, axis=-1)  # 变为 (样本数, 128, max_pad_length, 1) 适配 CNN\n",
    "y = np.array(y)\n",
    "\n",
    "print(f\"✅ X shape: {X.shape}\")  # 应该是 (样本数, 128, 128, 1)\n",
    "print(f\"✅ y shape: {y.shape}\")\n",
    "print(f\"✅ X min: {np.min(X)}, X max: {np.max(X)}\")  # 确保数据在 [0,1] 之间\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d5a65693-f0c5-4c58-b5db-b510bb429c1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ y shape after one-hot encoding: (1440, 8)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# 在将 y 转换为 one-hot 编码之前，将标签减去 1，确保标签值从 0 开始\n",
    "y = np.array(y) - 1  # 将标签减去 1，确保标签范围是 [0, 7]\n",
    "\n",
    "# 将 y 转换为 one-hot 编码\n",
    "y = to_categorical(y, num_classes=8)  # 8 是情绪类别的数量\n",
    "\n",
    "# 确保 y 的形状正确\n",
    "print(f\"✅ y shape after one-hot encoding: {y.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "460a3cd4-85f7-422a-953f-95614f8a550e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "36/36 [==============================] - 10s 269ms/step - loss: 2.0864 - accuracy: 0.1345 - val_loss: 2.0473 - val_accuracy: 0.1562\n",
      "Epoch 2/30\n",
      "36/36 [==============================] - 12s 323ms/step - loss: 2.0157 - accuracy: 0.1858 - val_loss: 1.9707 - val_accuracy: 0.2674\n",
      "Epoch 3/30\n",
      "36/36 [==============================] - 11s 316ms/step - loss: 1.8776 - accuracy: 0.2821 - val_loss: 1.9748 - val_accuracy: 0.2465\n",
      "Epoch 4/30\n",
      "36/36 [==============================] - 11s 313ms/step - loss: 1.7068 - accuracy: 0.3533 - val_loss: 1.8612 - val_accuracy: 0.2882\n",
      "Epoch 5/30\n",
      "36/36 [==============================] - 11s 297ms/step - loss: 1.5516 - accuracy: 0.4314 - val_loss: 1.9862 - val_accuracy: 0.2986\n",
      "Epoch 6/30\n",
      "36/36 [==============================] - 11s 296ms/step - loss: 1.4140 - accuracy: 0.4722 - val_loss: 2.0199 - val_accuracy: 0.3021\n",
      "Epoch 7/30\n",
      "36/36 [==============================] - 11s 300ms/step - loss: 1.3063 - accuracy: 0.5234 - val_loss: 1.9422 - val_accuracy: 0.3194\n",
      "Epoch 8/30\n",
      "36/36 [==============================] - 12s 327ms/step - loss: 1.1659 - accuracy: 0.5668 - val_loss: 2.0857 - val_accuracy: 0.3438\n",
      "Epoch 9/30\n",
      "36/36 [==============================] - 12s 346ms/step - loss: 1.0550 - accuracy: 0.6102 - val_loss: 2.1642 - val_accuracy: 0.3542\n",
      "Epoch 10/30\n",
      "36/36 [==============================] - 12s 329ms/step - loss: 1.0023 - accuracy: 0.6328 - val_loss: 2.0778 - val_accuracy: 0.3576\n",
      "Epoch 11/30\n",
      "36/36 [==============================] - 11s 315ms/step - loss: 0.8752 - accuracy: 0.6806 - val_loss: 2.3435 - val_accuracy: 0.3611\n",
      "Epoch 12/30\n",
      "36/36 [==============================] - 11s 305ms/step - loss: 0.7456 - accuracy: 0.7352 - val_loss: 2.5550 - val_accuracy: 0.3646\n",
      "Epoch 13/30\n",
      "36/36 [==============================] - 11s 303ms/step - loss: 0.6981 - accuracy: 0.7413 - val_loss: 2.3513 - val_accuracy: 0.3993\n",
      "Epoch 14/30\n",
      "36/36 [==============================] - 11s 319ms/step - loss: 0.5868 - accuracy: 0.7752 - val_loss: 2.4792 - val_accuracy: 0.3785\n",
      "Epoch 15/30\n",
      "36/36 [==============================] - 11s 315ms/step - loss: 0.5112 - accuracy: 0.8194 - val_loss: 2.8632 - val_accuracy: 0.3819\n",
      "Epoch 16/30\n",
      "36/36 [==============================] - 12s 321ms/step - loss: 0.4357 - accuracy: 0.8385 - val_loss: 3.0978 - val_accuracy: 0.3854\n",
      "Epoch 17/30\n",
      "36/36 [==============================] - 14s 390ms/step - loss: 0.3856 - accuracy: 0.8559 - val_loss: 3.2248 - val_accuracy: 0.3681\n",
      "Epoch 18/30\n",
      "36/36 [==============================] - 13s 349ms/step - loss: 0.4020 - accuracy: 0.8576 - val_loss: 2.9848 - val_accuracy: 0.4062\n",
      "Epoch 19/30\n",
      "36/36 [==============================] - 12s 337ms/step - loss: 0.3518 - accuracy: 0.8672 - val_loss: 3.2254 - val_accuracy: 0.3993\n",
      "Epoch 20/30\n",
      "36/36 [==============================] - 13s 348ms/step - loss: 0.3061 - accuracy: 0.8915 - val_loss: 3.8592 - val_accuracy: 0.3819\n",
      "Epoch 21/30\n",
      "36/36 [==============================] - 12s 331ms/step - loss: 0.3013 - accuracy: 0.8950 - val_loss: 3.1334 - val_accuracy: 0.4132\n",
      "Epoch 22/30\n",
      "36/36 [==============================] - 14s 375ms/step - loss: 0.2557 - accuracy: 0.9132 - val_loss: 4.1532 - val_accuracy: 0.3924\n",
      "Epoch 23/30\n",
      "36/36 [==============================] - 13s 360ms/step - loss: 0.2438 - accuracy: 0.9062 - val_loss: 3.8147 - val_accuracy: 0.4236\n",
      "Epoch 24/30\n",
      "36/36 [==============================] - 12s 327ms/step - loss: 0.2598 - accuracy: 0.8976 - val_loss: 3.6096 - val_accuracy: 0.3889\n",
      "Epoch 25/30\n",
      "36/36 [==============================] - 11s 311ms/step - loss: 0.2240 - accuracy: 0.9201 - val_loss: 3.6346 - val_accuracy: 0.4306\n",
      "Epoch 26/30\n",
      "36/36 [==============================] - 11s 311ms/step - loss: 0.1953 - accuracy: 0.9297 - val_loss: 3.7878 - val_accuracy: 0.4132\n",
      "Epoch 27/30\n",
      "36/36 [==============================] - 12s 321ms/step - loss: 0.1659 - accuracy: 0.9436 - val_loss: 3.7519 - val_accuracy: 0.4132\n",
      "Epoch 28/30\n",
      "36/36 [==============================] - 12s 335ms/step - loss: 0.1698 - accuracy: 0.9427 - val_loss: 3.9699 - val_accuracy: 0.4028\n",
      "Epoch 29/30\n",
      "36/36 [==============================] - 12s 346ms/step - loss: 0.1350 - accuracy: 0.9462 - val_loss: 4.3233 - val_accuracy: 0.4375\n",
      "Epoch 30/30\n",
      "36/36 [==============================] - 12s 340ms/step - loss: 0.1648 - accuracy: 0.9453 - val_loss: 4.2302 - val_accuracy: 0.4097\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x22d149daa60>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# 构建 CNN 模型\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 1)),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Flatten(),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(len(LABELS), activation='softmax')  # 输出层，类别数与 LABELS 的长度一致\n",
    "])\n",
    "\n",
    "# 编译模型\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# 训练模型\n",
    "model.fit(X, y, batch_size=32, epochs=30, validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1646021b-a257-468f-ae3a-8cb9a752d679",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
